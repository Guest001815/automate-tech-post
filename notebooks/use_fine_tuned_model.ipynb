{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -q git+https://github.com/huggingface/peft.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def make_inference(topic):\n",
    "  batch = tokenizer(f\"### INSTRUCTION\\nBelow summary for a blog post, \\\n",
    "                    please write a social media post\\\n",
    "                    \\n\\n### Topic:\\n{topic}\\n### Social media post:\\n\", return_tensors='pt')\n",
    "\n",
    "  with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(**batch, max_new_tokens=200)\n",
    "\n",
    "  display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "  # Set up user name and model name\n",
    "  hf_username = \"lgfunderburk\"\n",
    "  model_name = 'numpy-social-media-post'\n",
    "  peft_model_id = f\"{hf_username}/{model_name}\"\n",
    "\n",
    "  # Apply PETF configuration, setup model and autotokenizer\n",
    "  config = PeftConfig.from_pretrained(peft_model_id)\n",
    "  model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=False, device_map='auto')\n",
    "  tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "  \n",
    "  # Load the Lora model\n",
    "  model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "\n",
    "  # Summary to generate a social media post about\n",
    "  topic = \"The blog post demonstrates how to use JupySQL and DuckDB to query CSV files with SQL in a Jupyter notebook. \\\n",
    "          It covers installation, setup, querying, and converting queries to DataFrame. \\\n",
    "          Additionally, the post shows how to register SQLite user-defined functions (UDF), \\\n",
    "          connect to a SQLite database with spaces, switch connections between databases, and connect to existing engines. \\\n",
    "          It also provides tips for using JupySQL in Databricks, ignoring deprecation warnings, and hiding connection strings.\"\n",
    "  \n",
    "\n",
    "  # Generate social media post\n",
    "  make_inference(topic)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
